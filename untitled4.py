# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XbfOl9sK52S5EYH8lwF4vSJKYJOd_UHj
"""

import random
import torch
import pandas as pd
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier

# -----------------------
# Simulated Streaming Data
# -----------------------
def simulate_stream_data(n=100):
    data = {
        'bitrate': np.random.randint(1000, 6000, n),
        'buffering_events': np.random.randint(0, 5, n),
        'latency_ms': np.random.randint(50, 500, n),
        'view_duration_min': np.random.randint(1, 120, n),
        'viewer_messages': random.choices([
            "This stream is awesome!",
            "It's buffering a lot!",
            "LAG!",
            "Smooth and clean.",
            "Too much delay",
            "Great quality!"
        ], k=n),
        'satisfaction_label': np.random.choice([0, 1], n)  # 1=satisfied, 0=not
    }
    return pd.DataFrame(data)

df = simulate_stream_data()

# -----------------------
# Deep Neural Network for Satisfaction Prediction
# -----------------------
features = ['bitrate', 'buffering_events', 'latency_ms', 'view_duration_min']
X = StandardScaler().fit_transform(df[features])
y = df['satisfaction_label']

dnn = MLPClassifier(hidden_layer_sizes=(32, 16), max_iter=500, random_state=42)
dnn.fit(X, y)

def predict_satisfaction(sample):
    x = StandardScaler().fit_transform(sample[features])
    return dnn.predict_proba(x)[:, 1]  # probability of satisfaction

# -----------------------
# Sentiment Analysis using BERT
# -----------------------
tokenizer = BertTokenizer.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
model = BertForSequenceClassification.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")

def analyze_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=1)
    sentiment_score = torch.argmax(probs).item() + 1  # score from 1 (negative) to 5 (positive)
    return sentiment_score

# -----------------------
# QoS Decision Engine
# -----------------------
def qos_decision(satisfaction_prob, sentiment_score):
    if satisfaction_prob < 0.4 or sentiment_score <= 2:
        return "‚ö†Ô∏è Reduce bitrate or reroute to better CDN."
    elif satisfaction_prob > 0.7 and sentiment_score >= 4:
        return "‚úÖ Maintain current QoS."
    else:
        return "‚öôÔ∏è Monitor stream and optimize adaptively."

# -----------------------
# Example: Real-Time Simulation
# -----------------------
sample = df.sample(1)
satisfaction_prob = predict_satisfaction(sample)[0]
sentiment_score = analyze_sentiment(sample['viewer_messages'].values[0])
decision = qos_decision(satisfaction_prob, sentiment_score)

print("Sample Stream Data:")
print(sample[features | ['viewer_messages']])
print(f"\nüß† Predicted Satisfaction Probability: {satisfaction_prob:.2f}")
print(f"üí¨ Sentiment Score (1-5): {sentiment_score}")
print(f"üì° QoS Decision: {decision}")



